import vertica_python
from pymongo import MongoClient, UpdateOne
from itertools import groupby
import datetime
from decimal import Decimal
import json

# ==============================================================================
# PART 1: CONFIGURATION
# ==============================================================================
VERTICA_CONN_INFO = {
    'host': '172.26.133.65',
    'port': 5433,
    'user': 'P6600566',
    'password': 'P@6600566',
    'database': 'BAACDWH',
    'read_timeout': 600,
    'tlsmode': 'disable'
}

MONGO_URI = 'mongodb://admin:password@eden206.kube.baac.or.th:27044/'
MONGO_DB = 'CDP'
MONGO_COLLECTION = 'address'

BATCH_SIZE = 2000 # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏•‡∏á‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÄ‡∏û‡∏£‡∏≤‡∏∞ 1 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏à‡∏™‡∏£‡πâ‡∏≤‡∏á 2 operations
MASTER_DATE_COL = "row_updated_at" 

# ==============================================================================
# PART 2: MAPPING CONFIGURATION
# ==============================================================================
ADDRESS_MAPPINGS = [
    {
        "source": "CBS",
        "category": "CARDID",
        "cols": {
            "houseNo": "card_houseno", 
            "villageNo": "PMOO",
            "road": "card_road",       
            "subdistrict": "ZPSDISCD",
            "district": "PCITY",
            "province": "PSTATE",
            "postalCode": "PZIP",
            "country": "PCNTRY",
            "updatedAt": "row_updated_at"
        }
    },
    {
        "source": "CBS",
        "category": "HOME",
        "cols": {
            "houseNo": "home_houseno",
            "villageNo": "MMOO",
            "road": "home_road",
            "subdistrict": "ZMSDISCD",
            "district": "MCITY",
            "province": "MSTATE",
            "postalCode": "MZIP",
            "country": "MCNTRY",
            "updatedAt": "row_updated_at"
        }
    },
    {
        "source": "CBS",
        "category": "WORK",
        "cols": {
            "houseNo": "work_houseno",
            "villageNo": "ZOMOO",
            "road": "work_road",
            "subdistrict": "ZOSDISCD",
            "district": "ZOCITY",
            "province": "ZOSTATE",
            "postalCode": "ZOZIP",
            "country": "ZOCNTRY",
            "updatedAt": "row_updated_at"
        }
    }
]

# ==============================================================================
# PART 3: HELPER FUNCTIONS
# ==============================================================================

def format_date(dt):
    if isinstance(dt, (datetime.date, datetime.datetime)):
        return dt.isoformat()
    return None

def clean_decimal(val):
    if isinstance(val, Decimal):
        return int(val) if val % 1 == 0 else float(val)
    return val

def sanitize_text(val):
    if val is None: return None
    val_str = str(val).strip()
    if val_str == "": return None
    cleaned_chars = [c for c in val_str if (0x0e00 <= ord(c) <= 0x0e7f) or (32 <= ord(c) <= 126)]
    result = "".join(cleaned_chars).strip()
    return result if result else None

def build_address_object(row, rule, calculated_status):
    cols = rule['cols']
    
    raw_houseno = row.get(cols.get('houseNo'))
    final_houseno = sanitize_text(raw_houseno)
    
    if not final_houseno: return None

    return {
        "source": rule['source'],
        "category": rule['category'],
        "fieldUpdatedAt": format_date(row.get(cols.get('updatedAt'))),
        "houseNo": final_houseno,
        "villageNo": clean_decimal(row.get(cols.get('villageNo'))), 
        "road": sanitize_text(row.get(cols.get('road'))),
        "subdistrictKhwaeng": sanitize_text(row.get(cols.get('subdistrict'))),
        "districtKhet": sanitize_text(row.get(cols.get('district'))),
        "province": sanitize_text(row.get(cols.get('province'))),
        "postalCode": sanitize_text(row.get(cols.get('postalCode'))),
        "country": sanitize_text(row.get(cols.get('country'))) or "‡πÑ‡∏ó‡∏¢",
        "status": calculated_status
    }

# [NEW] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á Address ‡∏ó‡∏µ‡πà Active ‡∏≠‡∏¢‡∏π‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô MongoDB (‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Source/Category)
def get_current_active_address(mongo_doc, source, category):
    if not mongo_doc or 'addresses' not in mongo_doc:
        return None
    
    # ‡∏ß‡∏ô‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Active ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Source ‡πÅ‡∏•‡∏∞ Category
    for addr in mongo_doc['addresses']:
        if addr.get('status') == 'Active' and \
           addr.get('source') == source and \
           addr.get('category') == category:
            return addr
    return None

# [NEW] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)
def is_address_identical(new_addr, old_addr):
    if not old_addr: return False
    
    # field ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    ignored_keys = {'fieldUpdatedAt', 'status', 'lastModified'}
    
    for key, val in new_addr.items():
        if key in ignored_keys: continue
        # ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡πà‡∏≤ (‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå)
        if str(val) != str(old_addr.get(key)):
            return False
            
    return True

# ==============================================================================
# PART 4: MAIN EXECUTION
# ==============================================================================

def run_full_migration():
    print("üöÄ Starting Migration Process (Smart Update Mode)...")
    
    mongo_client = MongoClient(MONGO_URI)
    collection = mongo_client[MONGO_DB][MONGO_COLLECTION]

    try:
        with vertica_python.connect(**VERTICA_CONN_INFO) as conn:
            cursor = conn.cursor()

            query = """
            SELECT 
                ACN,
                DATE_KEY AS row_updated_at,
                -- [1. CARDID]
                TRIM(NVL(CAST(PAD1 AS VARCHAR), '') || ' ' || NVL(CAST(PAD2 AS VARCHAR), '')) AS card_houseno,
                PAD3 AS card_road, PMOO, ZPSDISCD, PCITY, PSTATE, PCNTRY, PZIP,
                -- [2. HOME]
                TRIM(NVL(CAST(MAD1 AS VARCHAR), '') || ' ' || NVL(CAST(MAD2 AS VARCHAR), '')) AS home_houseno,
                MAD3 AS home_road, MMOO, ZMSDISCD, MCITY, MSTATE, MCNTRY, MZIP,
                -- [3. WORK]
                TRIM(NVL(CAST(ZOAD1 AS VARCHAR), '') || ' ' || NVL(CAST(ZOAD2 AS VARCHAR), '')) AS work_houseno,
                ZOAD3 AS work_road, ZOMOO, ZOSDISCD, ZOCITY, ZOSTATE, ZOCNTRY, ZOZIP
            FROM DA_PROD.cleansing_TB_CBS_CIF_20251130
            WHERE ACN > 2000000
            ORDER BY ACN
            LIMIT 5000
            """
            
            print("‚è≥ Executing SQL Query...")
            cursor.execute(query)
            columns = [desc[0] for desc in cursor.description]
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Memory (List of Dicts)
            all_rows = [dict(zip(columns, row)) for row in cursor.fetchall()]
            
            # Group ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° ACN (‡∏ï‡πâ‡∏≠‡∏á sort ‡∏Å‡πà‡∏≠‡∏ô groupby ‡πÄ‡∏™‡∏°‡∏≠)
            all_rows.sort(key=lambda x: x['ACN'])
            grouped_data = {k: list(v) for k, v in groupby(all_rows, key=lambda x: x['ACN'])}
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å MongoDB
            cif_list = [str(k) for k in grouped_data.keys()]
            print(f"üîÑ Fetching existing data for {len(cif_list)} CIFs from MongoDB...")
            
            existing_cursor = collection.find(
                {"cif": {"$in": cif_list}},
                {"cif": 1, "addresses": 1}
            )
            existing_docs_map = {doc['cif']: doc for doc in existing_cursor}
            
            bulk_ops = []
            stats = {"updated_timestamp": 0, "appended_new": 0}

            print("üîÑ Processing Data & Building Operations...")

            for cif_raw, rows_list in grouped_data.items():
                cif_str = str(cif_raw)
                
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô
                rows_list.sort(key=lambda r: r.get(MASTER_DATE_COL) or datetime.datetime.min, reverse=True)
                
                # ‡πÄ‡∏Å‡πá‡∏ö Address ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞ process ‡∏à‡∏≤‡∏Å Vertica
                # (Logic ‡πÄ‡∏î‡∏¥‡∏°: ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡πÄ‡∏õ‡πá‡∏ô Active, ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ Inactive)
                # ‡πÅ‡∏ï‡πà‡πÉ‡∏ô Smart Update ‡πÄ‡∏£‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß Active ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á Vertica ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö MongoDB
                
                latest_row = rows_list[0] # ‡πÅ‡∏ñ‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                
                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ô‡∏ô‡∏µ‡πâ
                mongo_doc = existing_docs_map.get(cif_str)
                
                # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏™‡∏£‡πâ‡∏≤‡∏á Address Object ‡∏ï‡∏≤‡∏° Mapping (HOME, WORK, CARDID)
                for rule in ADDRESS_MAPPINGS:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Object ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà (‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô Active ‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô)
                    new_addr_obj = build_address_object(latest_row, rule, "Active")
                    
                    if not new_addr_obj: continue
                    
                    target_source = new_addr_obj['source']
                    target_category = new_addr_obj['category']
                    
                    # ‡∏´‡∏≤ Active Address ‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô Mongo
                    current_active_addr = get_current_active_address(mongo_doc, target_source, target_category)
                    
                    # ------------------------------------------------------------------
                    # CASE 1: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏õ‡πä‡∏∞ (Update Timestamp Only)
                    # ------------------------------------------------------------------
                    if current_active_addr and is_address_identical(new_addr_obj, current_active_addr):
                        
                        new_updated_at = new_addr_obj['fieldUpdatedAt']
                        
                        op_touch = UpdateOne(
                            {'cif': cif_str},
                            {'$set': {'addresses.$[elem].fieldUpdatedAt': new_updated_at}},
                            array_filters=[{
                                'elem.source': target_source,
                                'elem.category': target_category,
                                'elem.status': 'Active'
                            }],
                            upsert=False
                        )
                        bulk_ops.append(op_touch)
                        stats["updated_timestamp"] += 1
                        
                    # ------------------------------------------------------------------
                    # CASE 2: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡∏´‡∏£‡∏∑‡∏≠ ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà (Deactivate -> Push)
                    # ------------------------------------------------------------------
                    else:
                        # Op 1: ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤ ‡πÉ‡∏´‡πâ Deactivate ‡∏Å‡πà‡∏≠‡∏ô
                        if current_active_addr:
                            op_deactivate = UpdateOne(
                                {'cif': cif_str},
                                {'$set': {'addresses.$[elem].status': 'Inactive'}},
                                array_filters=[{
                                    'elem.source': target_source,
                                    'elem.category': target_category,
                                    'elem.status': 'Active'
                                }],
                                upsert=False
                            )
                            bulk_ops.append(op_deactivate)
                        
                        # Op 2: Push ‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
                        op_push = UpdateOne(
                            {'cif': cif_str},
                            {
                                '$push': {'addresses': new_addr_obj}
                            },
                            upsert=True
                        )
                        bulk_ops.append(op_push)
                        stats["appended_new"] += 1

                # Execute Bulk Write
                if len(bulk_ops) >= BATCH_SIZE:
                    collection.bulk_write(bulk_ops, ordered=True)
                    print(f"   -> Executed batch operations...")
                    bulk_ops = []

            # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
            if bulk_ops:
                collection.bulk_write(bulk_ops, ordered=True)
                
            print(f"\nüìä Summary:")
            print(f"   - Timestamp Updated (No Change): {stats['updated_timestamp']}")
            print(f"   - New Address Appended (Changed): {stats['appended_new']}")
                
    except Exception as e:
        print(f"‚ùå Error Occurred: {e}")
        import traceback
        traceback.print_exc()
    finally:
        mongo_client.close()
        print(f"\n‚úÖ Job Finished!")

if __name__ == "__main__":
    run_full_migration()