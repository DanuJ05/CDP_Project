import vertica_python
from pymongo import MongoClient, UpdateOne
from itertools import groupby
import datetime
from decimal import Decimal
import json
import re
# ==============================================================================
# PART 1: CONFIGURATION
# ==============================================================================
VERTICA_CONN_INFO = {
    'host': '172.26.133.65',
    'port': 5433,
    'user': 'P6600566',
    'password': 'P@6600566',
    'database': 'BAACDWH',
    'read_timeout': 600,
    'tlsmode': 'disable'
}

MONGO_URI = 'mongodb://admin:password@eden206.kube.baac.or.th:27044/'
MONGO_DB = 'CDP'
MONGO_COLLECTION = 'info'
BATCH_SIZE = 2000

FIXED_SOURCE_VALUE = "CBS"
SORT_DATE_COL = "DATE_KEY" 

# ==============================================================================
# PART 2: MAPPING CONFIGURATION
# ==============================================================================
PROFILE_MAPPING = {
    "ACN": "cif",
    "ZTITLE": "title",
    "FNAME": "firstName",
    "LNM": "lastName",
    "ZCIZID": "nationalId",
    "SEX": "gender",
    "NATION": "nationality",
    "ZKTBCCODE": "customerTypeCode",
    "DOB": "birthDate",
    "DOD": "deathDate",
    "MAR": "maritalStatus",
    "ZSPOUSETITLE": "spouseTitle",
    "ZSPOUSENM": "spouseName",
    "ZSPOUSELNM": "spouseLastName",
    "ZSPOUSEID": "spouseID",
    "DATE_KEY": "fieldUpdatedAt",
    "REC_STATUS": "status"
}

# ==============================================================================
# PART 3: HELPER FUNCTIONS
# ==============================================================================

def sanitize_text(val):
    if val is None: return None
    val_str = str(val).strip()
    if val_str == "": return None
    cleaned_chars = [c for c in val_str if (0x0e00 <= ord(c) <= 0x0e7f) or (32 <= ord(c) <= 126)]
    result = "".join(cleaned_chars).strip()
    return result if result else None

def format_date_iso(dt):
    if isinstance(dt, (datetime.date, datetime.datetime)):
        return dt.isoformat()
    return None

def format_date_simple(dt):
    if isinstance(dt, datetime.datetime):
        return dt.date().isoformat()
    elif isinstance(dt, datetime.date):
        return dt.isoformat()
    return str(dt) if dt else None

def clean_value(val):
    if isinstance(val, Decimal):
        return int(val) if val % 1 == 0 else float(val)
    if isinstance(val, str):
        return sanitize_text(val)
    return val

def build_profile_entry(row, calculated_status):
    entry = { "source": FIXED_SOURCE_VALUE }
    for vertica_col, mongo_key in PROFILE_MAPPING.items():
        if vertica_col == "ACN": continue 
        raw_val = row.get(vertica_col)
        
        if mongo_key in ["birthDate", "deathDate"]:
            entry[mongo_key] = format_date_simple(raw_val)
        elif mongo_key == "fieldUpdatedAt":
            entry[mongo_key] = format_date_iso(raw_val)
        elif mongo_key == "status":
            entry[mongo_key] = clean_value(raw_val) if raw_val else calculated_status
        else:
            entry[mongo_key] = clean_value(raw_val)
    return entry

# [NEW] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏≤ Active Profile ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô MongoDB
def get_current_active_profile(mongo_doc):
    if not mongo_doc or 'profile' not in mongo_doc:
        return None
    # ‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Active (‡∏ï‡∏≤‡∏° Logic Append)
    for p in reversed(mongo_doc['profile']):
        if p.get('status') == 'Active':
            return p
    return None

# [NEW] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÑ‡∏°‡πà‡∏ô‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞)
def is_data_identical(new_data, old_data):
    if not old_data: return False
    
    # keys ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    ignored_keys = {'fieldUpdatedAt', 'status', 'lastModified'}
    
    # ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ó‡∏∏‡∏Å key ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô new_data
    for key, val in new_data.items():
        if key in ignored_keys: continue
        # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (convert ‡πÄ‡∏õ‡πá‡∏ô str ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö)
        if str(val) != str(old_data.get(key)):
            return False
            
    return True

# ==============================================================================
# PART 4: MAIN EXECUTION
# ==============================================================================

def run_profile_migration():
    print("üöÄ Starting Customer Profile Migration (Smart Update)...")
    
    mongo_client = MongoClient(MONGO_URI)
    collection = mongo_client[MONGO_DB][MONGO_COLLECTION]

    try:
        with vertica_python.connect(**VERTICA_CONN_INFO) as conn:
            cursor = conn.cursor()

            query = """
            SELECT 
            ACN,ZCIZID,ZTITLE,FNAME,LNM,ZETITLE,ZEFNAME,ZELNM,
            SEX,DOB,DOD,NATION,MAR,ZKTBCCODE,
            ZSPOUSEID,ZSPOUSETITLE,ZSPOUSENM,ZSPOUSELNM,
            DATE_KEY
            FROM DA_PROD.cleansing_TB_CBS_CIF_20251130
            WHERE ACN > 2000000
            ORDER BY ACN 
            LIMIT 5000 
            """
            
            print("‚è≥ Executing SQL Query...")
            cursor.execute(query)
            columns = [desc[0] for desc in cursor.description]
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ Memory ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å Limit 5000 ‡πÑ‡∏°‡πà‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å)
            # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£ Pre-fetch MongoDB
            all_rows = [dict(zip(columns, row)) for row in cursor.fetchall()]
            
            # Group ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° ACN
            all_rows.sort(key=lambda x: x['ACN']) # groupby ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ sorted data
            grouped_data = {k: list(v) for k, v in groupby(all_rows, key=lambda x: x['ACN'])}
            
            # Extract CIF List ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å MongoDB ‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            cif_list = [str(k) for k in grouped_data.keys()]
            
            print(f"üîÑ Fetching existing data for {len(cif_list)} CIFs from MongoDB...")
            
            # [Optimization] ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏°‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏™‡πà Dict ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£ Query ‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≠‡∏ö
            existing_cursor = collection.find(
                {"cif": {"$in": cif_list}},
                {"cif": 1, "profile": 1}
            )
            existing_docs_map = {doc['cif']: doc for doc in existing_cursor}

            bulk_ops = []
            stats = {"updated_timestamp": 0, "appended_new": 0}

            print("üîÑ Comparing and Building Operations...")

            for cif_raw, rows_list in grouped_data.items():
                cif = str(cif_raw)
                
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô
                rows_list.sort(key=lambda r: r.get(SORT_DATE_COL) or datetime.datetime.min, reverse=True)
                
                # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ record ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Vertica ‡∏°‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ
                latest_row = rows_list[0]
                new_profile_entry = build_profile_entry(latest_row, "Active")
                
                # ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÉ‡∏ô Map
                old_doc = existing_docs_map.get(cif)
                current_active = get_current_active_profile(old_doc)
                
                # =========================================================
                # LOGIC: Compare -> Decide
                # =========================================================
                
                # CASE 1: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏õ‡πä‡∏∞ (Update Timestamp Only)
                if current_active and is_data_identical(new_profile_entry, current_active):
                    
                    new_date = new_profile_entry['fieldUpdatedAt']
                    
                    # ‡∏™‡∏±‡πà‡∏á Update ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ fieldUpdatedAt ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà Active ‡∏≠‡∏¢‡∏π‡πà
                    op_touch = UpdateOne(
                        {"cif": cif},
                        {"$set": {"profile.$[elem].fieldUpdatedAt": new_date}},
                        array_filters=[{"elem.status": "Active"}]
                    )
                    bulk_ops.append(op_touch)
                    stats["updated_timestamp"] += 1
                    
                # CASE 2: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡∏´‡∏£‡∏∑‡∏≠ ‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà (Deactivate Old -> Push New)
                else:
                    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤ ‡∏ï‡πâ‡∏≠‡∏á Deactivate ‡∏Å‡πà‡∏≠‡∏ô
                    if current_active:
                        op_deactivate = UpdateOne(
                            {"cif": cif},
                            {"$set": {"profile.$[elem].status": "Inactive"}},
                            array_filters=[{"elem.status": "Active"}]
                        )
                        bulk_ops.append(op_deactivate)

                    # Push ‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
                    op_push = UpdateOne(
                        {"cif": cif},
                        {
                            "$push": { "profile": new_profile_entry },
                             # Optional: Update Last Modified Doc
                            # "$set": { "lastModified": datetime.datetime.now() }
                        },
                        upsert=True
                    )
                    bulk_ops.append(op_push)
                    stats["appended_new"] += 1

                # Execute Bulk Write ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡πÜ
                if len(bulk_ops) >= BATCH_SIZE:
                    collection.bulk_write(bulk_ops, ordered=True)
                    bulk_ops = []
                    print(f"   -> Processed batch...")

            # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
            if bulk_ops:
                collection.bulk_write(bulk_ops, ordered=True)
                
            print(f"\nüìä Summary:")
            print(f"   - Timestamp Updated (Data Unchanged): {stats['updated_timestamp']}")
            print(f"   - New Data Appended (Data Changed/New): {stats['appended_new']}")
                
    except Exception as e:
        print(f"‚ùå Error Occurred: {e}")
        import traceback
        traceback.print_exc()
    finally:
        mongo_client.close()
        print(f"\n‚úÖ Job Finished!")

if __name__ == "__main__":
    run_profile_migration()